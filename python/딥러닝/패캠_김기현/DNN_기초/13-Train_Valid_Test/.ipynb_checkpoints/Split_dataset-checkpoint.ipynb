{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e942cab-6273-469a-986c-b3e3d398e1f3",
   "metadata": {},
   "source": [
    "# Split into Train / Valid / Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b19e7c4-bb87-47d2-8b9f-531f000c7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99adcb43-ba21-43f0-92dd-fe47a2ceb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1445abef-3c38-439e-bc92-76c8d1937ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  Target  \n",
       "20635    -121.09   0.781  \n",
       "20636    -121.21   0.771  \n",
       "20637    -121.22   0.923  \n",
       "20638    -121.32   0.847  \n",
       "20639    -121.24   0.894  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "df['Target'] = california.target\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c043e-5797-4748-b414-fd4fd6e6f20c",
   "metadata": {},
   "source": [
    "## Convert to PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3ec695-4a54-48e1-a79a-a517187818ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d77576b-f10d-4660-b018-60eb3a6e2133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20640, 8]) torch.Size([20640, 1])\n"
     ]
    }
   ],
   "source": [
    "data = torch.from_numpy(df.values).float() # numpy value를 float 형태의 tensor type으로 변환\n",
    "\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1:]\n",
    "\n",
    "print(x.size(), y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8324d0-6178-48cc-aa83-6d7f9401db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Valid / Test ratio\n",
    "ratios = [.6, .2, .2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c66e4f5-db9e-4524-ba6f-bbdd7bab8fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 12384 / Valid 4128 / Test 4128 \n"
     ]
    }
   ],
   "source": [
    "train_cnt = int(data.size(0) * ratios[0])\n",
    "valid_cnt = int(data.size(0) * ratios[1])\n",
    "test_cnt = int(data.size(0) * ratios[2])\n",
    "\n",
    "cnts = [train_cnt, valid_cnt, test_cnt]\n",
    "\n",
    "print(f\"Train {cnts[0]} / Valid {cnts[1]} / Test {cnts[2]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed24a485-171c-4c2d-bf5b-bf9c560f4cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12384, 8]) torch.Size([12384, 1])\n",
      "torch.Size([4128, 8]) torch.Size([4128, 1])\n",
      "torch.Size([4128, 8]) torch.Size([4128, 1])\n"
     ]
    }
   ],
   "source": [
    "# Shuffle before split.\n",
    "\n",
    "indices = torch.randperm(data.size(0))\n",
    "x = torch.index_select(x, dim=0, index=indices)\n",
    "y = torch.index_select(y, dim=0, index=indices)\n",
    "\n",
    "# Split train, valid and test set with each count.\n",
    "x = list(x.split(cnts, dim=0)) # tensor.split([list]) # list index대로 쪼개준다.\n",
    "y = y.split(cnts, dim=0)\n",
    "\n",
    "\n",
    "for x_i, y_i in zip(x, y):\n",
    "    print(x_i.size(), y_i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e640f2-60dd-4e5b-b2c4-629d5eff8b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9483,  6374, 18088,  ...,  7965, 17983, 10515])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354ad6f-2aa2-4bc0-b580-d0bac033610b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b6321f4-0d45-40b0-a869-d923f449a7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x[0].numpy()) # 반드시 train data에 대해서만 fit을 진행해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9131ee58-1589-441b-aecf-62a43f0f5a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12379</th>\n",
       "      <td>-2.423824</td>\n",
       "      <td>-2.333177</td>\n",
       "      <td>-2.250677</td>\n",
       "      <td>-2.636867</td>\n",
       "      <td>-1.276590</td>\n",
       "      <td>-0.245926</td>\n",
       "      <td>-16.055618</td>\n",
       "      <td>59.396297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12380</th>\n",
       "      <td>-2.198083</td>\n",
       "      <td>-2.213493</td>\n",
       "      <td>-2.441204</td>\n",
       "      <td>-2.853574</td>\n",
       "      <td>-1.276878</td>\n",
       "      <td>-0.232682</td>\n",
       "      <td>-16.992752</td>\n",
       "      <td>60.148212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12381</th>\n",
       "      <td>-2.029637</td>\n",
       "      <td>-2.263886</td>\n",
       "      <td>-2.373974</td>\n",
       "      <td>-2.976616</td>\n",
       "      <td>-1.276540</td>\n",
       "      <td>-0.247103</td>\n",
       "      <td>-16.292646</td>\n",
       "      <td>59.275993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12382</th>\n",
       "      <td>-1.980859</td>\n",
       "      <td>-2.175698</td>\n",
       "      <td>-2.155669</td>\n",
       "      <td>-2.754537</td>\n",
       "      <td>-1.277268</td>\n",
       "      <td>-0.254385</td>\n",
       "      <td>-16.744751</td>\n",
       "      <td>60.005352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12383</th>\n",
       "      <td>-1.996772</td>\n",
       "      <td>-2.219792</td>\n",
       "      <td>-2.306451</td>\n",
       "      <td>-3.067005</td>\n",
       "      <td>-1.277188</td>\n",
       "      <td>-0.255304</td>\n",
       "      <td>-16.329956</td>\n",
       "      <td>59.268475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "12379 -2.423824 -2.333177 -2.250677  -2.636867   -1.276590 -0.245926   \n",
       "12380 -2.198083 -2.213493 -2.441204  -2.853574   -1.276878 -0.232682   \n",
       "12381 -2.029637 -2.263886 -2.373974  -2.976616   -1.276540 -0.247103   \n",
       "12382 -1.980859 -2.175698 -2.155669  -2.754537   -1.277268 -0.254385   \n",
       "12383 -1.996772 -2.219792 -2.306451  -3.067005   -1.277188 -0.255304   \n",
       "\n",
       "        Latitude  Longitude  \n",
       "12379 -16.055618  59.396297  \n",
       "12380 -16.992752  60.148212  \n",
       "12381 -16.292646  59.275993  \n",
       "12382 -16.744751  60.005352  \n",
       "12383 -16.329956  59.268475  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] = torch.from_numpy(scaler.transform(x[0].numpy())).float()\n",
    "x[1] = torch.from_numpy(scaler.transform(x[1].numpy())).float()\n",
    "x[2] = torch.from_numpy(scaler.transform(x[2].numpy())).float()\n",
    "\n",
    "df = pd.DataFrame(x[0].numpy(), columns=california.feature_names)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c54ce86-aa08-48ef-a902-b094a6985c24",
   "metadata": {},
   "source": [
    "# Build Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe65d19f-60de-465d-aa53-4ce31cdb8d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=8, out_features=6, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=6, out_features=5, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=5, out_features=4, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(x[0].size(-1), 6),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(6, 5),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(5, 4),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(4, 3),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(3, y[0].size(-1)),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f5a52b4-8c4d-4948-abf5-db2f413a0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6e29e7-56fe-4c85-bd13-3480116f2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figures\n",
    "n_epochs = 10000\n",
    "batch_size = 1024\n",
    "print_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1edb8b4-02ce-4005-9655-3b0717d4948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "lowest_loss = np.inf\n",
    "best_model = None\n",
    "\n",
    "early_stop = 500\n",
    "lowest_epoch = np.inf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4dd6fa3-2a78-447e-b5fc-00985df82e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyeul\\AppData\\Local\\Temp\\ipykernel_21624\\459308043.py:20: UserWarning: Using a target size (torch.Size([1024, 8])) that is different to the input size (torch.Size([1024, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat_i, y_i)\n",
      "C:\\Users\\kyeul\\AppData\\Local\\Temp\\ipykernel_21624\\459308043.py:20: UserWarning: Using a target size (torch.Size([96, 8])) that is different to the input size (torch.Size([96, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat_i, y_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: train loss=469.53219, valid_loss=3.86609, lowest_loss=3.86828\n",
      "Epoch 200: train loss=469.59066, valid_loss=3.62598, lowest_loss=3.62695\n",
      "Epoch 300: train loss=469.64407, valid_loss=3.55613, lowest_loss=3.55699\n",
      "Epoch 400: train loss=469.49367, valid_loss=3.48160, lowest_loss=3.48213\n",
      "Epoch 500: train loss=469.60239, valid_loss=3.43616, lowest_loss=3.43632\n",
      "Epoch 600: train loss=469.63051, valid_loss=3.42937, lowest_loss=3.42871\n",
      "Epoch 700: train loss=469.55365, valid_loss=3.43824, lowest_loss=3.42871\n",
      "Epoch 800: train loss=469.46285, valid_loss=3.45215, lowest_loss=3.42871\n",
      "Epoch 900: train loss=469.54902, valid_loss=3.47184, lowest_loss=3.42871\n",
      "Epoch 1000: train loss=469.58745, valid_loss=3.49615, lowest_loss=3.42871\n",
      "There is no improvement during last 500 epochs.\n",
      "The best validation loss from epoch 582 : 3.428708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_history, valid_history = [], []\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    # Shuffle before mini-batch split.\n",
    "    indices = torch.randperm(x[0].size(0))\n",
    "    x_ = torch.index_select(x[0], dim=0, index=indices)\n",
    "    y_ = torch.index_select(x[0], dim=0, index=indices)\n",
    "    \n",
    "    # |x_| = (train_data_size, input_dim)\n",
    "    # |y_| = (train_data_size, output_dim)\n",
    "    \n",
    "    x_ = x_.split(batch_size, dim=0)\n",
    "    y_ = y_.split(batch_size, dim=0)\n",
    "    \n",
    "    train_loss, valid_loss = 0, 0\n",
    "    y_hat = []\n",
    "    \n",
    "    for x_i, y_i in zip(x_, y_):\n",
    "        y_hat_i = model(x_i)\n",
    "        loss = F.mse_loss(y_hat_i, y_i)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += float(loss)\n",
    "    \n",
    "    train_loss = train_loss / len(x_)\n",
    "    \n",
    "    # You need to declare to PYTORCH to stop build the compuation graph.\n",
    "    # validation \n",
    "    with torch.no_grad(): # gradient를 사용하지 말 것. # 파라미터를 하지 않음\n",
    "        # You don't need to shuffle the validation set.\n",
    "        # Only split is needed.\n",
    "        x_ = x[1].split(batch_size, dim=0)\n",
    "        y_ = y[1].split(batch_size, dim=0)\n",
    "        \n",
    "        valid_loss = 0\n",
    "        \n",
    "        # validation_size/batch_size 만큼 반복\n",
    "        for x_i, y_i in zip(x_, y_):\n",
    "            y_hat_i = model(x_i)\n",
    "            loss = F.mse_loss(y_hat_i, y_i)\n",
    "\n",
    "            valid_loss += loss\n",
    "            y_hat += [y_hat_i]\n",
    "    \n",
    "    valid_loss = valid_loss / len(x_)\n",
    "    \n",
    "    # Log each loss to plot after training is done.\n",
    "    train_history += [train_loss]\n",
    "    valid_history += [valid_loss]\n",
    "    \n",
    "    if (i + 1) % print_interval == 0:\n",
    "        print(f\"Epoch {i+1}: train loss={train_loss:.5f}, valid_loss={valid_loss:.5f}, lowest_loss={lowest_loss:.5f}\")\n",
    "    if valid_loss <= lowest_loss:\n",
    "        lowest_loss = valid_loss\n",
    "        lowest_epoch = i\n",
    "        \n",
    "        # 'state_dic()' return model weights as key-value\n",
    "        # Take a deep copy, if the valid loss is lowest ever.\n",
    "        best_model = deepcopy(model.state_dict())\n",
    "    else:\n",
    "        if early_stop > 0 and lowest_epoch + early_stop < i + 1:\n",
    "            print(\"There is no improvement during last {} epochs.\".format(early_stop))\n",
    "            break\n",
    "\n",
    "print(\"The best validation loss from epoch {} : {:4f}\".format(lowest_epoch + 1, lowest_loss))\n",
    "\n",
    "# Load best epoch's model.\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27245303-77b1-44d4-bfe7-589a104f10ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
