{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97879a93-d596-4540-a63f-05ccf7f95282",
   "metadata": {},
   "source": [
    "# GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33122d9-7b81-401a-afc1-12bb0ae9d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70af2e4a-2a87-4ae9-a0c1-2ec661172ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000],\n",
       "        [0.4000, 0.5000, 0.6000],\n",
       "        [0.7000, 0.8000, 0.9000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.FloatTensor([[0.1, 0.2, 0.3],\n",
    "                            [0.4, 0.5, 0.6],\n",
    "                            [0.7, 0.8, 0.9]])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81336a28-ef6f-4ca8-be65-53429018ba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5354, 0.7055, 0.9260],\n",
       "        [0.9693, 0.3723, 0.5890],\n",
       "        [0.3125, 0.3422, 0.2985]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand_like(target)\n",
    "\n",
    "# 아래 코드는 최종 스칼라 값이 x로 미분된다는 것을 뜻함\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb25e50-039c-4c7c-a077-15ffe4a840d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2110, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.mse_loss(x, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38019fbd-617d-4b41-a8dc-9dae3ce2bb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Loss: 0.09444469958543777\n",
      "tensor([[0.6541, 0.5584, 0.0372],\n",
      "        [0.7159, 0.3582, 0.5254],\n",
      "        [0.7731, 0.3368, 0.9120]], requires_grad=True)\n",
      "2-th Loss: 0.0746229737997055\n",
      "tensor([[0.5925, 0.5186, 0.0664],\n",
      "        [0.6808, 0.3740, 0.5337],\n",
      "        [0.7650, 0.3883, 0.9107]], requires_grad=True)\n",
      "3-th Loss: 0.05896135792136192\n",
      "tensor([[0.5378, 0.4832, 0.0923],\n",
      "        [0.6496, 0.3880, 0.5411],\n",
      "        [0.7578, 0.4340, 0.9095]], requires_grad=True)\n",
      "4-th Loss: 0.04658675566315651\n",
      "tensor([[0.4891, 0.4517, 0.1154],\n",
      "        [0.6219, 0.4004, 0.5476],\n",
      "        [0.7514, 0.4747, 0.9084]], requires_grad=True)\n",
      "5-th Loss: 0.0368092842400074\n",
      "tensor([[0.4459, 0.4238, 0.1359],\n",
      "        [0.5972, 0.4115, 0.5534],\n",
      "        [0.7456, 0.5108, 0.9075]], requires_grad=True)\n",
      "6-th Loss: 0.02908387780189514\n",
      "tensor([[0.4075, 0.3989, 0.1541],\n",
      "        [0.5753, 0.4213, 0.5586],\n",
      "        [0.7406, 0.5430, 0.9067]], requires_grad=True)\n",
      "7-th Loss: 0.0229798574000597\n",
      "tensor([[0.3733, 0.3768, 0.1703],\n",
      "        [0.5558, 0.4301, 0.5632],\n",
      "        [0.7361, 0.5715, 0.9059]], requires_grad=True)\n",
      "8-th Loss: 0.018156923353672028\n",
      "tensor([[0.3429, 0.3571, 0.1848],\n",
      "        [0.5385, 0.4378, 0.5673],\n",
      "        [0.7321, 0.5969, 0.9053]], requires_grad=True)\n",
      "9-th Loss: 0.014346210286021233\n",
      "tensor([[0.3159, 0.3397, 0.1976],\n",
      "        [0.5231, 0.4447, 0.5709],\n",
      "        [0.7285, 0.6195, 0.9047]], requires_grad=True)\n",
      "10-th Loss: 0.011335276067256927\n",
      "tensor([[0.2919, 0.3242, 0.2089],\n",
      "        [0.5094, 0.4509, 0.5742],\n",
      "        [0.7253, 0.6395, 0.9042]], requires_grad=True)\n",
      "11-th Loss: 0.008956268429756165\n",
      "tensor([[0.2706, 0.3104, 0.2191],\n",
      "        [0.4973, 0.4563, 0.5770],\n",
      "        [0.7225, 0.6574, 0.9037]], requires_grad=True)\n",
      "12-th Loss: 0.007076558191329241\n",
      "tensor([[0.2517, 0.2981, 0.2281],\n",
      "        [0.4865, 0.4612, 0.5796],\n",
      "        [0.7200, 0.6732, 0.9033]], requires_grad=True)\n",
      "13-th Loss: 0.00559135340154171\n",
      "tensor([[0.2348, 0.2872, 0.2360],\n",
      "        [0.4769, 0.4655, 0.5819],\n",
      "        [0.7178, 0.6873, 0.9029]], requires_grad=True)\n",
      "14-th Loss: 0.00441786041483283\n",
      "tensor([[0.2198, 0.2775, 0.2432],\n",
      "        [0.4683, 0.4693, 0.5839],\n",
      "        [0.7158, 0.6998, 0.9026]], requires_grad=True)\n",
      "15-th Loss: 0.0034906549844890833\n",
      "tensor([[0.2065, 0.2689, 0.2495],\n",
      "        [0.4607, 0.4727, 0.5857],\n",
      "        [0.7141, 0.7110, 0.9023]], requires_grad=True)\n",
      "16-th Loss: 0.0027580484747886658\n",
      "tensor([[0.1947, 0.2612, 0.2551],\n",
      "        [0.4540, 0.4758, 0.5873],\n",
      "        [0.7125, 0.7208, 0.9021]], requires_grad=True)\n",
      "17-th Loss: 0.002179198432713747\n",
      "tensor([[0.1842, 0.2544, 0.2601],\n",
      "        [0.4480, 0.4785, 0.5887],\n",
      "        [0.7111, 0.7296, 0.9018]], requires_grad=True)\n",
      "18-th Loss: 0.0017218360444530845\n",
      "tensor([[0.1748, 0.2484, 0.2645],\n",
      "        [0.4427, 0.4809, 0.5899],\n",
      "        [0.7099, 0.7375, 0.9016]], requires_grad=True)\n",
      "19-th Loss: 0.0013604627456516027\n",
      "tensor([[0.1665, 0.2430, 0.2685],\n",
      "        [0.4379, 0.4830, 0.5910],\n",
      "        [0.7088, 0.7444, 0.9014]], requires_grad=True)\n",
      "20-th Loss: 0.0010749335633590817\n",
      "tensor([[0.1591, 0.2382, 0.2720],\n",
      "        [0.4337, 0.4849, 0.5920],\n",
      "        [0.7078, 0.7506, 0.9013]], requires_grad=True)\n",
      "21-th Loss: 0.0008493303903378546\n",
      "tensor([[0.1525, 0.2340, 0.2751],\n",
      "        [0.4300, 0.4866, 0.5929],\n",
      "        [0.7069, 0.7561, 0.9011]], requires_grad=True)\n",
      "22-th Loss: 0.000671075948048383\n",
      "tensor([[0.1467, 0.2302, 0.2778],\n",
      "        [0.4266, 0.4881, 0.5937],\n",
      "        [0.7062, 0.7610, 0.9010]], requires_grad=True)\n",
      "23-th Loss: 0.0005302327335812151\n",
      "tensor([[0.1415, 0.2269, 0.2803],\n",
      "        [0.4237, 0.4894, 0.5944],\n",
      "        [0.7055, 0.7653, 0.9009]], requires_grad=True)\n",
      "24-th Loss: 0.0004189494939055294\n",
      "tensor([[0.1369, 0.2239, 0.2825],\n",
      "        [0.4210, 0.4906, 0.5950],\n",
      "        [0.7049, 0.7692, 0.9008]], requires_grad=True)\n",
      "25-th Loss: 0.00033102172892540693\n",
      "tensor([[0.1328, 0.2212, 0.2844],\n",
      "        [0.4187, 0.4916, 0.5956],\n",
      "        [0.7043, 0.7726, 0.9007]], requires_grad=True)\n",
      "26-th Loss: 0.0002615480334497988\n",
      "tensor([[0.1292, 0.2189, 0.2862],\n",
      "        [0.4166, 0.4925, 0.5961],\n",
      "        [0.7038, 0.7756, 0.9006]], requires_grad=True)\n",
      "27-th Loss: 0.00020665528427343816\n",
      "tensor([[0.1259, 0.2168, 0.2877],\n",
      "        [0.4148, 0.4934, 0.5965],\n",
      "        [0.7034, 0.7783, 0.9006]], requires_grad=True)\n",
      "28-th Loss: 0.00016328325727954507\n",
      "tensor([[0.1230, 0.2149, 0.2891],\n",
      "        [0.4131, 0.4941, 0.5969],\n",
      "        [0.7030, 0.7807, 0.9005]], requires_grad=True)\n",
      "29-th Loss: 0.00012901386071462184\n",
      "tensor([[0.1205, 0.2132, 0.2903],\n",
      "        [0.4117, 0.4948, 0.5972],\n",
      "        [0.7027, 0.7829, 0.9004]], requires_grad=True)\n",
      "30-th Loss: 0.00010193677735514939\n",
      "tensor([[0.1182, 0.2118, 0.2914],\n",
      "        [0.4104, 0.4953, 0.5975],\n",
      "        [0.7024, 0.7848, 0.9004]], requires_grad=True)\n",
      "31-th Loss: 8.054260251810774e-05\n",
      "tensor([[0.1162, 0.2105, 0.2923],\n",
      "        [0.4092, 0.4959, 0.5978],\n",
      "        [0.7021, 0.7865, 0.9004]], requires_grad=True)\n",
      "32-th Loss: 6.363864667946473e-05\n",
      "tensor([[0.1144, 0.2093, 0.2932],\n",
      "        [0.4082, 0.4963, 0.5981],\n",
      "        [0.7019, 0.7880, 0.9003]], requires_grad=True)\n",
      "33-th Loss: 5.028230953030288e-05\n",
      "tensor([[0.1128, 0.2083, 0.2939],\n",
      "        [0.4073, 0.4967, 0.5983],\n",
      "        [0.7017, 0.7893, 0.9003]], requires_grad=True)\n",
      "34-th Loss: 3.972926060669124e-05\n",
      "tensor([[0.1114, 0.2074, 0.2946],\n",
      "        [0.4065, 0.4971, 0.5985],\n",
      "        [0.7015, 0.7905, 0.9002]], requires_grad=True)\n",
      "35-th Loss: 3.139096952509135e-05\n",
      "tensor([[0.1101, 0.2065, 0.2952],\n",
      "        [0.4058, 0.4974, 0.5986],\n",
      "        [0.7013, 0.7916, 0.9002]], requires_grad=True)\n",
      "36-th Loss: 2.4802731786621734e-05\n",
      "tensor([[0.1090, 0.2058, 0.2957],\n",
      "        [0.4051, 0.4977, 0.5988],\n",
      "        [0.7012, 0.7925, 0.9002]], requires_grad=True)\n",
      "37-th Loss: 1.9597204300225712e-05\n",
      "tensor([[0.1080, 0.2052, 0.2962],\n",
      "        [0.4046, 0.4980, 0.5989],\n",
      "        [0.7011, 0.7933, 0.9002]], requires_grad=True)\n",
      "38-th Loss: 1.548424370412249e-05\n",
      "tensor([[0.1071, 0.2046, 0.2966],\n",
      "        [0.4040, 0.4982, 0.5990],\n",
      "        [0.7009, 0.7941, 0.9002]], requires_grad=True)\n",
      "39-th Loss: 1.2234480891493149e-05\n",
      "tensor([[0.1063, 0.2041, 0.2970],\n",
      "        [0.4036, 0.4984, 0.5992],\n",
      "        [0.7008, 0.7947, 0.9001]], requires_grad=True)\n",
      "40-th Loss: 9.666775440564379e-06\n",
      "tensor([[0.1056, 0.2036, 0.2973],\n",
      "        [0.4032, 0.4986, 0.5992],\n",
      "        [0.7007, 0.7953, 0.9001]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# GD를 바닥부터 구현해보자.\n",
    "\n",
    "threshold = 1e-5 # 이것보다 작으면 학습 완료\n",
    "lr = 0.5\n",
    "iter_cnt = 0\n",
    "\n",
    "while loss > threshold:\n",
    "    iter_cnt += 1\n",
    "    loss.backward() # loss에 대해서 x로 미분!\n",
    "    \n",
    "    x = x - lr * x.grad # 파라미터 업데이트 수식 그 자체\n",
    "    \n",
    "    x.detach_()\n",
    "    x.requires_grad_(True)\n",
    "    \n",
    "    loss = F.mse_loss(x, target) # loss update\n",
    "    \n",
    "    print('{}-th Loss: {}'.format(iter_cnt, loss))\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f2bd8a-1151-441b-bb88-51bcde32ee3b",
   "metadata": {},
   "source": [
    "오우 개쩐다! ㅋㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c7a338-e4e5-4c59-a66e-9bb477d13cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Loss: 0.12764540314674377\n",
      "tensor([[0.4387, 0.5932, 0.7869],\n",
      "        [0.8428, 0.4007, 0.5914],\n",
      "        [0.3986, 0.4440, 0.4322]], requires_grad=True)\n",
      "2-th Loss: 0.07721758633852005\n",
      "tensor([[0.3634, 0.5058, 0.6787],\n",
      "        [0.7444, 0.4228, 0.5933],\n",
      "        [0.4656, 0.5231, 0.5361]], requires_grad=True)\n",
      "3-th Loss: 0.04671187326312065\n",
      "tensor([[0.3049, 0.4378, 0.5945],\n",
      "        [0.6679, 0.4399, 0.5948],\n",
      "        [0.5177, 0.5846, 0.6170]], requires_grad=True)\n",
      "4-th Loss: 0.02825779654085636\n",
      "tensor([[0.2593, 0.3850, 0.5291],\n",
      "        [0.6083, 0.4533, 0.5960],\n",
      "        [0.5582, 0.6325, 0.6799]], requires_grad=True)\n",
      "5-th Loss: 0.017094220966100693\n",
      "tensor([[0.2239, 0.3439, 0.4782],\n",
      "        [0.5620, 0.4637, 0.5969],\n",
      "        [0.5897, 0.6697, 0.7288]], requires_grad=True)\n",
      "6-th Loss: 0.010340948589146137\n",
      "tensor([[0.1964, 0.3119, 0.4386],\n",
      "        [0.5260, 0.4717, 0.5976],\n",
      "        [0.6142, 0.6987, 0.7668]], requires_grad=True)\n",
      "7-th Loss: 0.006255635991692543\n",
      "tensor([[0.1750, 0.2870, 0.4078],\n",
      "        [0.4980, 0.4780, 0.5981],\n",
      "        [0.6333, 0.7212, 0.7964]], requires_grad=True)\n",
      "8-th Loss: 0.0037842723540961742\n",
      "tensor([[0.1583, 0.2677, 0.3838],\n",
      "        [0.4762, 0.4829, 0.5985],\n",
      "        [0.6481, 0.7387, 0.8195]], requires_grad=True)\n",
      "9-th Loss: 0.002289251424372196\n",
      "tensor([[0.1454, 0.2527, 0.3652],\n",
      "        [0.4593, 0.4867, 0.5989],\n",
      "        [0.6596, 0.7523, 0.8374]], requires_grad=True)\n",
      "10-th Loss: 0.0013848560629412532\n",
      "tensor([[0.1353, 0.2410, 0.3507],\n",
      "        [0.4461, 0.4897, 0.5991],\n",
      "        [0.6686, 0.7629, 0.8513]], requires_grad=True)\n",
      "11-th Loss: 0.0008377523627132177\n",
      "tensor([[0.1274, 0.2319, 0.3394],\n",
      "        [0.4359, 0.4920, 0.5993],\n",
      "        [0.6756, 0.7712, 0.8621]], requires_grad=True)\n",
      "12-th Loss: 0.0005067887250334024\n",
      "tensor([[0.1213, 0.2248, 0.3307],\n",
      "        [0.4279, 0.4937, 0.5995],\n",
      "        [0.6810, 0.7776, 0.8705]], requires_grad=True)\n",
      "13-th Loss: 0.000306575937429443\n",
      "tensor([[0.1166, 0.2193, 0.3239],\n",
      "        [0.4217, 0.4951, 0.5996],\n",
      "        [0.6852, 0.7826, 0.8771]], requires_grad=True)\n",
      "14-th Loss: 0.00018545950297266245\n",
      "tensor([[0.1129, 0.2150, 0.3186],\n",
      "        [0.4169, 0.4962, 0.5997],\n",
      "        [0.6885, 0.7864, 0.8822]], requires_grad=True)\n",
      "15-th Loss: 0.0001121915047406219\n",
      "tensor([[0.1100, 0.2117, 0.3144],\n",
      "        [0.4131, 0.4971, 0.5997],\n",
      "        [0.6911, 0.7894, 0.8861]], requires_grad=True)\n",
      "16-th Loss: 6.786889571230859e-05\n",
      "tensor([[0.1078, 0.2091, 0.3112],\n",
      "        [0.4102, 0.4977, 0.5998],\n",
      "        [0.6930, 0.7918, 0.8892]], requires_grad=True)\n",
      "17-th Loss: 4.105653351871297e-05\n",
      "tensor([[0.1061, 0.2071, 0.3087],\n",
      "        [0.4079, 0.4982, 0.5998],\n",
      "        [0.6946, 0.7936, 0.8916]], requires_grad=True)\n",
      "18-th Loss: 2.4836692318785936e-05\n",
      "tensor([[0.1047, 0.2055, 0.3068],\n",
      "        [0.4062, 0.4986, 0.5999],\n",
      "        [0.6958, 0.7950, 0.8935]], requires_grad=True)\n",
      "19-th Loss: 1.5024671483843122e-05\n",
      "tensor([[0.1037, 0.2043, 0.3053],\n",
      "        [0.4048, 0.4989, 0.5999],\n",
      "        [0.6967, 0.7961, 0.8949]], requires_grad=True)\n",
      "20-th Loss: 9.089000741369091e-06\n",
      "tensor([[0.1029, 0.2033, 0.3041],\n",
      "        [0.4037, 0.4992, 0.5999],\n",
      "        [0.6975, 0.7970, 0.8961]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# lr을 바꿔보자. 어떤 변화가 있을까.\n",
    "\n",
    "threshold = 1e-5 # 이것보다 작으면 학습 완료\n",
    "lr = 1.\n",
    "iter_cnt = 0\n",
    "\n",
    "while loss > threshold:\n",
    "    iter_cnt += 1\n",
    "    loss.backward() # loss에 대해서 x로 미분!\n",
    "    \n",
    "    x = x - lr * x.grad # 파라미터 업데이트 수식 그 자체\n",
    "    \n",
    "    x.detach_()\n",
    "    x.requires_grad_(True)\n",
    "    \n",
    "    loss = F.mse_loss(x, target) # loss update\n",
    "    \n",
    "    print('{}-th Loss: {}'.format(iter_cnt, loss))\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0a1ff-0784-4461-82e8-ab86679e0b87",
   "metadata": {},
   "source": [
    "오차는 좀 크지만 훨씬 빨리 수렴했네."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f526c-9894-47a1-837c-cd182220dfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
