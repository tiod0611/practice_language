{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cef7d93-6126-4cf9-8d6b-8a52aaa7f67f",
   "metadata": {},
   "source": [
    "# 네이버 영화 리뷰 감성분석\n",
    "\n",
    "최소한의 성능이라도 작동하는 코드를 작성하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2db6161-fa3a-4747-9295-c2c24d83f89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyeul\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "\n",
    "import wandb\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch_optimizer as custom_optim\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72890de0-0514-4f8e-aa89-0fe286e1e253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgyul611\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef2ad39-030c-4d09-b9bd-8279cbe3b323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xeke1rp8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = wandb.util.generate_id()\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191c653b-f5b3-432f-8cf5-e1dd6ffb315c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Kyeul\\Desktop\\code\\practice\\practice_language\\python\\Deeplearning\\huggingface\\tutorials\\Binary_Classification_\\wandb\\run-20231119_004440-xeke1rp8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gyul611/Binary_Classification_nsmc/runs/xeke1rp8' target=\"_blank\">binary_nsmc</a></strong> to <a href='https://wandb.ai/gyul611/Binary_Classification_nsmc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gyul611/Binary_Classification_nsmc' target=\"_blank\">https://wandb.ai/gyul611/Binary_Classification_nsmc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gyul611/Binary_Classification_nsmc/runs/xeke1rp8' target=\"_blank\">https://wandb.ai/gyul611/Binary_Classification_nsmc/runs/xeke1rp8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gyul611/Binary_Classification_nsmc/runs/xeke1rp8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1f15c3d8910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wandb.init(project=\"Binary_Classification_nsmc\",\n",
    "           entity=\"gyul611\",\n",
    "           id=id,\n",
    "           name=\"binary_nsmc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f89ef8-9c40-4e30-a69f-1217fbff8592",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be537c3-132a-4a5e-b4e5-fc6d61abe675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "nsmc_dataset = load_dataset('nsmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afbf14a-af5d-4374-b3a8-de3b0599e691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796c0f5-d9d1-4ec4-a58a-e036c4ae358a",
   "metadata": {},
   "source": [
    "간단한 EDA를 통해 데이터 분포와 특징을 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95420984-4b86-4bf3-9aa4-b9a3fd05c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data move to dataFrame\n",
    "nsmc_df = nsmc_dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf04581b-d452-4d0c-894f-8ebf0e3648d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75173</td>\n",
       "      <td>75173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74827</td>\n",
       "      <td>74827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  document\n",
       "label                 \n",
       "0      75173     75173\n",
       "1      74827     74827"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1c19f-9abb-400f-9d50-21d4b3a295da",
   "metadata": {},
   "source": [
    "label 분포는 적당하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19128a3-2683-42a1-b38d-f97ed4905d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    150000.000000\n",
       "mean         35.203353\n",
       "std          29.532097\n",
       "min           0.000000\n",
       "25%          16.000000\n",
       "50%          27.000000\n",
       "75%          42.000000\n",
       "max         146.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_df['length'] = nsmc_df['document'].str.len()\n",
    "nsmc_df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e56a1a-8748-455a-aaeb-d44606d7fa7f",
   "metadata": {},
   "source": [
    "0-0 base line  \n",
    "리뷰인데, 최솟값이 0인 것이 보인다.   \n",
    "추후에 데이터를 자세히 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0eb8b27-94cc-4dcb-b004-c2da1469e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Aurguement\n",
    "batch_size = 256\n",
    "max_length = 146\n",
    "warmup_ratio = 0.05\n",
    "pretrained_model = \"klue/roberta-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0b6fa-a9ba-41b2-9998-c3bda72fa737",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "1. train 데이터를 random하게 shuffleing한다.\n",
    "2. train 데이터를 train과 valid셋으로 나눈다.\n",
    "3. DataLoader에 주입하고 batch 별 데이터에 맞게 collate를 수행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a2781e8-c07d-47da-81dd-464b8f99a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_split(data, valid_ratio=.2):\n",
    "    data, labels = data['document'], data['label']\n",
    "\n",
    "    # label-index map을 만듬(해당 task에서는 label이 이미 숫자이므로 수행할 필요는 없지만 \n",
    "    # 범용성을 위해 수행)\n",
    "    unique_labels = list(set(labels))\n",
    "    label_to_index = {}\n",
    "    index_to_label = {}\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        label_to_index[label] = i\n",
    "        index_to_label[i] = label\n",
    "\n",
    "    # label value를 integer value로 convert 수행\n",
    "    labels = list(map(label_to_index.get, labels))\n",
    "\n",
    "    # Shuffle before split into train and validation set\n",
    "    shuffled = list(zip(data, labels))\n",
    "    random.shuffle(shuffled)\n",
    "    data = [element[0] for element in shuffled]\n",
    "    labels = [element[1] for element in shuffled]\n",
    "    idx = int(len(data) * (1 - valid_ratio)) # split할 경계의 index값\n",
    "\n",
    "    data = {\n",
    "\n",
    "        'train':{\n",
    "            'document':data[:idx],\n",
    "            'label':labels[:idx]\n",
    "        },\n",
    "        'validation':{\n",
    "            'document':data[idx:],\n",
    "            'label':labels[idx:]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return data, index_to_label\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e784b3bf-3157-430e-abd9-46d4af6feadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "data, index_to_label = shuffle_and_split(nsmc_dataset['train'])\n",
    "print(index_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0829c58b-ae5f-4e09-a825-a3803ea5146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationCollator():\n",
    "    def __init__(self, tokenizer, max_length, with_text=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.with_text = with_text # tokenization을 통과하면 text는 반환하지 않기 때문에 필요에 \n",
    "                                   # 따라 원본 텍스르도 함께 반환하도록 한다. \n",
    "\n",
    "    def __call__(self, samples):\n",
    "        texts, labels = [], []\n",
    "        for text, label in samples:\n",
    "            texts += [text]\n",
    "            labels += [label]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "\n",
    "        return_value = {\n",
    "            'input_ids':encoding['input_ids'],\n",
    "            'token_type_ids':encoding['token_type_ids'],\n",
    "            'attention_mask':encoding['attention_mask'],\n",
    "            'labels':torch.tensor(labels, dtype=torch.long),    \n",
    "        }\n",
    "        if self.with_text:\n",
    "            return_value['text'] = texts \n",
    "\n",
    "        return return_value\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf391b0-31f9-4044-b83f-f04396143559",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecccaa59-c5db-496b-8240-844bd216f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    TextClassificationDataset(data['train']['document'], data['train']['label']),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=TextClassificationCollator(tokenizer, max_length)\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    TextClassificationDataset(data['validation']['document'], data['validation']['label']),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=TextClassificationCollator(tokenizer, max_length)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "835947f7-da04-4777-b123-01ffa0f98be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120064\n",
      "30208\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader)*batch_size)\n",
    "print(len(valid_loader)*batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df0d8d-c24c-4182-8f63-23b426ebf6c4",
   "metadata": {},
   "source": [
    "## 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78b5088-d128-46ae-9d34-8c8d2a83c378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14e1c924-8154-412b-90d4-73ada5f72fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b77b7d2-3999-4840-bfd2-007bc314d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_iteration:  120064\n",
      "number of warmup steps:  6003\n"
     ]
    }
   ],
   "source": [
    "# set hyper-parameters\n",
    "epochs = 10\n",
    "learning_rate = 5e-3 # 0.0005\n",
    "n_total_iterations = len(train_loader)*batch_size\n",
    "n_warmup_steps = int(n_total_iterations * warmup_ratio)\n",
    "\n",
    "print(\"total_iteration: \", n_total_iterations)\n",
    "print(\"number of warmup steps: \", n_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b6f024b-80f6-4516-bb07-bd87837e3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set AdamW\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a60da9c6-6ed4-4951-a8d9-6d215b2d1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set criterion\n",
    "crit = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6439839-cc9d-4689-8ead-ed6d677d9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    n_warmup_steps,\n",
    "    n_total_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cffe8f6-638a-4812-a95a-594d00ca7153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a947ef8d-992f-4896-bd81-7b59f5006c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred, label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ee097b3-dd49-47cb-9580-8480045d77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5de1e9-00cb-406b-872b-7cade22c4cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss: 0.69270\n",
      "batch loss: 0.69363\n",
      "batch loss: 0.69512\n",
      "batch loss: 0.68934\n",
      "batch loss: 0.69292\n",
      "batch loss: 0.69289\n",
      "batch loss: 0.69397\n",
      "batch loss: 0.69471\n",
      "batch loss: 0.69520\n",
      "batch loss: 0.69348\n",
      "batch loss: 0.69244\n",
      "batch loss: 0.69405\n",
      "batch loss: 0.69775\n",
      "batch loss: 0.69238\n",
      "batch loss: 0.69226\n",
      "batch loss: 0.69177\n",
      "batch loss: 0.68861\n",
      "batch loss: 0.69395\n",
      "batch loss: 0.69408\n",
      "batch loss: 0.69526\n",
      "batch loss: 0.69370\n",
      "batch loss: 0.69510\n",
      "batch loss: 0.69365\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        y_i = batch['labels'].to(device)\n",
    "\n",
    "        model.zero_grad() #??\n",
    "        y_hat_i = model(input_ids=input_ids, \n",
    "                        token_type_ids=token_type_ids, \n",
    "                        attention_mask=attention_mask).logits\n",
    "        # print(y_i.float())\n",
    "        # print(y_hat_i.t()[1])\n",
    "        # print(torch.sigmoid(y_hat_i.t()[1]))\n",
    "        # print(y_hat_i)\n",
    "       \n",
    "        loss = crit(torch.sigmoid(y_hat_i.t()[1]), y_i.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if step % 100 == 0:\n",
    "        #     print(f\"batch loss: {loss:.5f}\")\n",
    "        print(f\"batch loss: {loss:.5f}\")\n",
    "        # train_losses.append(loss.item())\n",
    "        # train_acc += get_accuracy(y_hat_i.argmax(dim=1), label)\n",
    "    \n",
    "\n",
    "    # print(\"Train loss: \", np.mean(train_losses))\n",
    "    # print(\"Train acc: \", train_acc/len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579bd362-bb15-4152-bdae-a6c5c8de504d",
   "metadata": {},
   "source": [
    "왜 Loss가 정상적으로 줄어들지 않을까?  \n",
    "loss function을 잘 못 설정했나?  \n",
    "optimizer는 제대로 작동하고 있나?  \n",
    "model의 output에 문제는 없는가?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad99bc-3e92-4643-9428-898734ed2f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
